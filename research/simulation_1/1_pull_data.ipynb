{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7d3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b315e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Methods\n",
    "def fetch_binance_klines(symbol, interval, start_time, end_time, limit=1000): \n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'startTime': int(start_time),\n",
    "        'endTime': int(end_time),\n",
    "        'limit': limit\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\"https://api.binance.com/api/v3/klines\", params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "def datetime_to_timestamp(dt_obj):\n",
    "    return int(dt_obj.timestamp() * 1000)\n",
    "\n",
    "def fetch_all_data(symbol, interval, start_time, end_time):\n",
    "    all_data = []\n",
    "    current_start = start_time\n",
    "    \n",
    "    start_timestamp = datetime_to_timestamp(current_start)\n",
    "    end_timestamp = datetime_to_timestamp(end_time)\n",
    "    \n",
    "    total_hours = int((end_timestamp - start_timestamp) / (1000 * 60 * 60))\n",
    "    print(f\"Total hours to fetch: {total_hours}\")\n",
    "    \n",
    "    batch_count = 0\n",
    "    \n",
    "    while current_start < end_time:\n",
    "        batch_end = current_start + timedelta(hours=999)\n",
    "        if batch_end > end_time:\n",
    "            batch_end = end_time\n",
    "            \n",
    "        start_ts = datetime_to_timestamp(current_start)\n",
    "        end_ts = datetime_to_timestamp(batch_end)\n",
    "        \n",
    "        print(f\"Fetching batch {batch_count + 1}: {current_start.strftime('%Y-%m-%d %H:%M')} to {batch_end.strftime('%Y-%m-%d %H:%M')}\")\n",
    "        \n",
    "        batch_data = fetch_binance_klines(symbol, interval, start_ts, end_ts)\n",
    "        \n",
    "        if batch_data:\n",
    "            all_data.extend(batch_data)\n",
    "            print(f\"  → Fetched {len(batch_data)} records\")\n",
    "        else:\n",
    "            print(\"  → Failed to fetch data for this batch\")\n",
    "            break\n",
    "            \n",
    "        # Move to next batch\n",
    "        current_start = batch_end + timedelta(hours=1)\n",
    "        batch_count += 1\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"Total records fetched: {len(all_data)}\")\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c63b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hours to fetch: 8760\n",
      "Fetching batch 1: 2024-11-01 00:00 to 2024-12-12 15:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 2: 2024-12-12 16:00 to 2025-01-23 07:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 3: 2025-01-23 08:00 to 2025-03-05 23:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 4: 2025-03-06 00:00 to 2025-04-16 15:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 5: 2025-04-16 16:00 to 2025-05-28 07:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 6: 2025-05-28 08:00 to 2025-07-08 23:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 7: 2025-07-09 00:00 to 2025-08-19 15:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 8: 2025-08-19 16:00 to 2025-09-30 07:00\n",
      "  → Fetched 1000 records\n",
      "Fetching batch 9: 2025-09-30 08:00 to 2025-11-01 00:00\n",
      "  → Fetched 761 records\n",
      "Total records fetched: 8761\n",
      "Data fetch completed successfully!\n"
     ]
    }
   ],
   "source": [
    "SYMBOL = \"ETHUSDT\"\n",
    "INTERVAL = \"1h\"\n",
    "\n",
    "# Previous default: end_time = (dt.datetime.now().replace(day=1) - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Set end_time to a specific month and year, such as September 2025:\n",
    "end_time = dt.datetime(year=2025, month=11, day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "start_time = end_time - timedelta(days=365)\n",
    "\n",
    "crypto_data = fetch_all_data(SYMBOL, INTERVAL, start_time, end_time)\n",
    "\n",
    "if crypto_data:\n",
    "    print(\"Data fetch completed successfully!\")\n",
    "else:\n",
    "    print(\"Failed to fetch data. Please check your internet connection and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f0c5cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process and save the data to CSV\n",
    "if not crypto_data:\n",
    "    exit()\n",
    "\n",
    "columns = [\n",
    "    'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "    'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "    'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "]\n",
    "df = pd.DataFrame(crypto_data, columns=columns)\n",
    "df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "price_columns = [\n",
    "    'open', 'high', 'low', 'close', 'volume',\n",
    "    'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume'\n",
    "]\n",
    "for col in price_columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "df = df.sort_values('open_time').reset_index(drop=True)\n",
    "df = df.drop('ignore', axis=1)\n",
    "filename = f\"./research/data/{SYMBOL}_hourly_data_{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}.csv\"\n",
    "df.to_csv(filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
